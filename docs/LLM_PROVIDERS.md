# Documenta√ß√£o do GTA - √çndice

## üìö Documenta√ß√£o Completa

### üìñ Documentos Principais
- [`README.md`](../README.md) - Vis√£o geral e instala√ß√£o do sistema
- [`HYBRID_WORKFLOW_SYSTEM.md`](./HYBRID_WORKFLOW_SYSTEM.md) - Documenta√ß√£o t√©cnica do sistema h√≠brido üÜï
- [`USAGE_GUIDE.md`](./USAGE_GUIDE.md) - Guia de uso das novas funcionalidades üÜï
- [`LLM_PROVIDERS.md`](./LLM_PROVIDERS.md) - Configura√ß√£o de provedores LLM

### üèóÔ∏è Arquitetura do Sistema
O GTA utiliza uma arquitetura multi-agente h√≠brida com:
- **Sistema de Workflow Inteligente** - Execu√ß√£o com retry e replanning autom√°tico
- **Valida√ß√£o Autom√°tica de C√≥digo** - Corre√ß√£o em tempo real usando LLM
- **Sa√≠da Estruturada** - Modelos Pydantic para consist√™ncia de dados
- **An√°lise de Confian√ßa** - Decis√µes baseadas em scores de confian√ßa

### üÜï Funcionalidades Avan√ßadas
- Valida√ß√£o autom√°tica de sintaxe Python
- Corre√ß√£o autom√°tica de erros via LLM
- Sistema de retry inteligente com aprendizado
- Feedback estruturado de erros
- Replanning din√¢mico baseado em contexto
- Metadados detalhados de execu√ß√£o

---

# Guia de Provedores LLM para o GTA

Este documento detalha como configurar e utilizar diferentes provedores LLM com o Git Terminal Assistant (GTA). agora suporta m√∫ltiplos provedores de LLM, permitindo escolher entre modelos locais (Ollama) ou APIs comerciais (OpenAI, Anthropic, Google, Cohere, Azure).

## Provedores Suportados

- **Ollama** (padr√£o) - Modelos locais, privacidade total
- **OpenAI** - GPT-4, GPT-3.5-turbo
- **Anthropic** - Claude 3 Opus, Sonnet
- **Google** - Gemini Pro, PaLM
- **Cohere** - Command, Command-Light
- **Azure OpenAI** - Deployment empresarial do OpenAI

## Configura√ß√£o R√°pida

### 1. Copie o arquivo de exemplo

```bash
cp .env.example .env
```

### 2. Configure seu provedor preferido

Edite `.env` e defina:

```bash
# Escolha o provedor
LLM_PROVIDER=openai  # ou anthropic, google, cohere, azure_openai, ollama

# Configure o modelo
LLM_MODEL=gpt-4

# Adicione sua API key
OPENAI_API_KEY=sua-chave-aqui
```

### 3. Instale as depend√™ncias

Op√ß√£o B (recomendado) ‚Äî arquivos separados:

```bash
# N√∫cleo (core)
pip install -r requirements.txt

# Provedores online
pip install -r requirements-providers.txt

# Tudo (n√∫cleo + provedores)
pip install -r requirements-all.txt
```

Alternativa ‚Äî instalar por provedor (apenas se/quando for usar):

```bash
# Para OpenAI
pip install langchain-openai

# Para Anthropic
pip install langchain-anthropic

# Para Google
pip install langchain-google-genai

# Para Cohere
pip install langchain-cohere

# Para Azure OpenAI
pip install langchain-openai
```

## Exemplos de Configura√ß√£o

### OpenAI

```bash
LLM_PROVIDER=openai
LLM_MODEL=gpt-4
OPENAI_API_KEY=sk-...
```

### Anthropic Claude

```bash
LLM_PROVIDER=anthropic
LLM_MODEL=claude-3-opus-20240229
ANTHROPIC_API_KEY=sk-ant-...
```

### Google Gemini

```bash
LLM_PROVIDER=google
LLM_MODEL=gemini-pro
GOOGLE_API_KEY=...
```

### Ollama Local

```bash
LLM_PROVIDER=ollama
LLM_MODEL=llama3.1:8b
OLLAMA_HOST=http://localhost:11434
```

### Azure OpenAI

```bash
LLM_PROVIDER=azure_openai
AZURE_OPENAI_API_KEY=...
AZURE_OPENAI_ENDPOINT=https://seu-recurso.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4
```

## Configura√ß√£o por Agente

Voc√™ pode usar modelos diferentes para cada agente:

```bash
# Modelo padr√£o
LLM_MODEL=llama3.1:8b

# Modelos espec√≠ficos por agente
GIT_AGENT_MODEL=gpt-4        # Commits mais inteligentes
CODE_AGENT_MODEL=claude-3     # Melhor gera√ß√£o de c√≥digo
CHAT_AGENT_MODEL=llama3.1:8b  # Chat local e privado
```

## Configura√ß√£o Avan√ßada

### Par√¢metros de Modelo

```bash
LLM_TEMPERATURE=0.3    # Criatividade (0.0-1.0)
LLM_MAX_TOKENS=2000    # Tamanho m√°ximo da resposta
LLM_TIMEOUT=60         # Timeout em segundos
```

### Fallback Autom√°tico

Se o provedor principal falhar, o sistema tentar√° alternativas:

```bash
FALLBACK_PROVIDERS=ollama,openai  # Tenta Ollama, depois OpenAI
FALLBACK_MODEL=llama3.1:8b        # Modelo para fallback
```

## Privacidade e Custos

| Provedor | Privacidade | Custo | Performance |
|----------|-------------|-------|-------------|
| Ollama | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Total | Gr√°tis | Depende do hardware |
| OpenAI | ‚≠ê‚≠ê API externa | Pago por uso | Excelente |
| Anthropic | ‚≠ê‚≠ê API externa | Pago por uso | Excelente |
| Google | ‚≠ê‚≠ê API externa | Pago/Gr√°tis limitado | Muito boa |
| Cohere | ‚≠ê‚≠ê API externa | Pago/Gr√°tis limitado | Boa |
| Azure | ‚≠ê‚≠ê‚≠ê Empresarial | Pago por uso | Excelente |

## Solu√ß√£o de Problemas

### Provider n√£o encontrado

```
Error: OpenAI provider requires: pip install langchain-openai
```

**Solu√ß√£o:** Instale a depend√™ncia necess√°ria.

### API Key inv√°lida

```
Error: OpenAI API key not found. Set OPENAI_API_KEY in .env
```

**Solu√ß√£o:** Verifique se o arquivo `.env` existe e cont√©m a chave correta.

### Fallback para Ollama

Se houver problemas com o provedor configurado, o sistema automaticamente tentar√° usar Ollama como fallback. Certifique-se de ter o Ollama instalado e rodando:

```bash
# Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Baixar modelo padr√£o
ollama pull llama3.1:8b

# Iniciar servidor
ollama serve
```

## Testando a Configura√ß√£o

Ap√≥s configurar, teste com:

```bash
# Teste interativo
gta -i
> What LLM provider am I using?

# Teste de commit (requer altera√ß√µes staged)
gta 'commit'
```

O sistema mostrar√° qual provedor e modelo est√° sendo usado durante a inicializa√ß√£o.

## Mantendo Compatibilidade

O sistema mant√©m total compatibilidade com a configura√ß√£o anterior via `config.py`. Se n√£o houver arquivo `.env`, o comportamento padr√£o com Ollama ser√° mantido.
